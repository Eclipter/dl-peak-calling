batch_size: 1024
dataset_number: 1
dataset_prefix: trigram
hidden_size: 32
loss_fn: nn.BCEWithLogitsLoss
lr: 0.001
num_epochs: 100
num_layers: 1
num_workers: 16
optimizer: optim.Adam
weight_decay: 1.0e-06
